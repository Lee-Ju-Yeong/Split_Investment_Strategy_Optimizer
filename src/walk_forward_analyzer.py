# src/walk_forward_analyzer.py

from __future__ import annotations

import sys
from pathlib import Path

# BOOTSTRAP: allow direct execution (`python src/walk_forward_analyzer.py`) while keeping package imports.
if __name__ == "__main__" and (__package__ is None or __package__ == ""):
    file_path = Path(__file__).resolve()
    sys.path.insert(0, str(file_path.parent.parent))
    __package__ = file_path.parent.name  # "src"

import os
from datetime import datetime, timedelta
from typing import TYPE_CHECKING

from .config_loader import load_config

if TYPE_CHECKING:
    import pandas as pd

# --- Clustering Helper Function ---
def find_robust_parameters(
    simulation_results_df: "pd.DataFrame",
    param_cols: list,
    metric_cols: list,
    k_range: tuple = (2, 11),
    min_cluster_size_ratio: float = 0.05
) -> tuple[dict, "pd.DataFrame | None"]:
    """
    K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ì—ì„œ ê°€ì¥ ê°•ê±´í•œ íŒŒë¼ë¯¸í„° ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.
    (WFO íŒŒì´í”„ë¼ì¸ì— í†µí•©í•˜ê¸° ìœ„í•´ ì‹œê°í™” ì½”ë“œëŠ” ì œê±°ëœ ë²„ì „)
    """
    import numpy as np
    import pandas as pd
    from sklearn.cluster import KMeans
    from sklearn.metrics import silhouette_score
    from sklearn.neighbors import NearestNeighbors
    from sklearn.preprocessing import StandardScaler

    print("\n--- 4a. Robust Parameter Search via Clustering ---")
    features = param_cols + metric_cols
    df = simulation_results_df[features].dropna()
    
    if df.empty or len(df) < k_range[0]:
        print("[Warning] Not enough data for clustering. Returning best result by Calmar.")
        best_by_calmar = simulation_results_df.sort_values('calmar_ratio', ascending=False).iloc[0]
        return best_by_calmar.to_dict(), None

    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(df)
    
    best_k, best_score = -1, -1
    k_candidates = range(k_range[0], min(k_range[1], len(df)))
    for k in k_candidates:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')
        cluster_labels = kmeans.fit_predict(scaled_features)
        if len(np.unique(cluster_labels)) < 2: continue
        score = silhouette_score(scaled_features, cluster_labels)
        if score > best_score:
            best_score = score
            best_k = k
            
    if best_k == -1: best_k = k_range[0] # Fallback
    print(f"  - Optimal k detected: {best_k} (Silhouette Score: {best_score:.4f})")
    
    kmeans = KMeans(n_clusters=best_k, random_state=42, n_init='auto')
    df['cluster'] = kmeans.fit_predict(scaled_features)
    
    cluster_summary = df.groupby('cluster')[metric_cols].mean()
    cluster_summary['size'] = df['cluster'].value_counts()
    
    # Z-score ê³„ì‚° ì‹œ ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²½ìš° ë°©ì§€
    calmar_std = cluster_summary['calmar_ratio'].std()
    denominator = calmar_std if calmar_std > 0 else 1
    cluster_summary['calmar_zscore'] = (cluster_summary['calmar_ratio'] - cluster_summary['calmar_ratio'].mean()) / denominator
    cluster_summary['robustness_score'] = cluster_summary['calmar_zscore'] * np.log1p(cluster_summary['size'])
    
    min_cluster_size = int(len(df) * min_cluster_size_ratio)
    qualified_clusters = cluster_summary[cluster_summary['size'] >= min_cluster_size]
    
    robust_cluster_id = qualified_clusters['robustness_score'].idxmax() if not qualified_clusters.empty else cluster_summary['robustness_score'].idxmax()
    print(f"  - Most robust cluster identified: Cluster {robust_cluster_id}")
    
    robust_cluster_df = df[df['cluster'] == robust_cluster_id]
    centroid = kmeans.cluster_centers_[robust_cluster_id]
    
    nn = NearestNeighbors(n_neighbors=1).fit(scaled_features[df.index.isin(robust_cluster_df.index)])
    _, indices = nn.kneighbors([centroid])
    
    closest_point_index = robust_cluster_df.index[indices[0][0]]
    best_params_series = simulation_results_df.loc[closest_point_index]
    
    # WFO ê²°ê³¼ ì €ì¥ì„ ìœ„í•´ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ê°€ í¬í•¨ëœ DF ë°˜í™˜
    clustered_df_full = df.reset_index().merge(simulation_results_df.drop(columns=features, errors='ignore'), left_on='index', right_index=True)
    
    return best_params_series.to_dict(), clustered_df_full
# --- ë¶„ì„ ë° ì‹œê°í™” í—¬í¼ í•¨ìˆ˜ ---
def plot_wfo_results(final_curve: "pd.Series", params_df: "pd.DataFrame", results_dir: str):
    """ìµœì¢… WFO ê²°ê³¼(ìˆ˜ìµê³¡ì„ , íŒŒë¼ë¯¸í„° ë¶„í¬)ë¥¼ ì‹œê°í™”í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns

    from .performance_analyzer import PerformanceAnalyzer

    print("\n" + "="*80)
    print("ğŸ¨ Generating WFO result plots...")
    print("="*80)
    
    # 1. ìµœì¢… WFO Equity Curve ë° MDD í”Œë¡¯
    history_df = pd.DataFrame(final_curve, columns=['total_value'])
    analyzer = PerformanceAnalyzer(history_df)
    
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15, 10), gridspec_kw={'height_ratios': [3, 1]})
    
    # Equity Curve
    ax1.set_title('Walk-Forward Optimization Equity Curve', fontsize=16)
    ax1.plot(analyzer.daily_values.index, analyzer.daily_values, color='b', label='Equity Curve')
    ax1.set_ylabel('Portfolio Value'); ax1.legend(loc='upper left'); ax1.grid(True)

    # Drawdown
    drawdown = (analyzer.daily_values - analyzer.daily_values.cummax()) / analyzer.daily_values.cummax()
    ax2.fill_between(drawdown.index, drawdown, 0, color='r', alpha=0.3, label='Drawdown')
    ax2.set_ylabel('Drawdown'); ax2.set_xlabel('Date'); ax2.legend(loc='upper left'); ax2.grid(True)
    
    plt.tight_layout()
    equity_curve_path = os.path.join(results_dir, "wfo_equity_curve.png")
    plt.savefig(equity_curve_path, dpi=300)
    plt.close()
    print(f"âœ… WFO Equity Curve plot saved to: {equity_curve_path}")

    # 2. íŒŒë¼ë¯¸í„° ì•ˆì •ì„±(ë¶„í¬) í”Œë¡¯
    numeric_params = params_df.select_dtypes(include='number').columns.drop('fold', errors='ignore')
    if not numeric_params.empty:
        cols = 3
        rows = (len(numeric_params) + cols - 1) // cols
        fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))
        axes = axes.flatten()

        for i, param in enumerate(numeric_params):
            sns.histplot(data=params_df, x=param, ax=axes[i], kde=True)
            axes[i].set_title(f'Distribution of {param}')
        
        for j in range(i + 1, len(axes)): fig.delaxes(axes[j])

        plt.tight_layout()
        param_dist_path = os.path.join(results_dir, "wfo_parameter_distribution.png")
        plt.savefig(param_dist_path, dpi=300); plt.close()
        print(f"âœ… Parameter Distribution plot saved to: {param_dist_path}")

# --- Orchestrator ë©”ì¸ ë¡œì§ ---

def run_walk_forward_analysis():
    """
    Walk-Forward Optimization í”„ë¡œì„¸ìŠ¤ ì „ì²´ë¥¼ ì´ê´„í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í•¨ìˆ˜.
    """
    import numpy as np
    import pandas as pd
    from tqdm import tqdm

    # ì‹¤ì œ ì›Œì»¤ í•¨ìˆ˜ ë° ë¶„ì„ ëª¨ë“ˆì€ GPU í™˜ê²½ì—ì„œë§Œ í•„ìš”í•˜ë¯€ë¡œ lazy import
    from .debug_gpu_single_run import run_single_backtest
    from .parameter_simulation_gpu import find_optimal_parameters
    from .performance_analyzer import PerformanceAnalyzer

    # 1. ì„¤ì • ë¡œë“œ
    config = load_config()
    wfo_settings = config['walk_forward_settings']
    backtest_settings = config['backtest_settings']
    initial_cash = backtest_settings['initial_cash'] 

    # 2. [í•µì‹¬] ëª¨ë“  ê¸°ê°„ íŒŒë¼ë¯¸í„° ìë™ ê³„ì‚°
    # --------------------------------------------------------------------------
    print("\n" + "="*80)
    print("ğŸš€ Starting Robustness-Focused Walk-Forward Optimization")

    # ì‚¬ìš©ì ì„¤ì •ê°’ ì¶”ì¶œ
    total_start_date = pd.to_datetime(backtest_settings['start_date'])
    total_end_date = pd.to_datetime(backtest_settings['end_date'])
    total_folds = wfo_settings['total_folds']
    period_length_days = wfo_settings['period_length_days']
        
    # --- í™•ì • WFO ê¸°ê°„ ìƒì„± (no-overlap ìš°ì„ , ë¶ˆê°€ ì‹œ ìµœì†Œ ê²¹ì¹¨ + ê· ë“±ë¶„í¬) ---
    S = pd.to_datetime(backtest_settings['start_date']).normalize()
    E = pd.to_datetime(backtest_settings['end_date']).normalize()
    N = int(wfo_settings['total_folds'])
    L_days = int(wfo_settings['period_length_days'])
    L = pd.Timedelta(days=L_days)

    if N <= 0 or L_days <= 0:
        raise ValueError("total_folds and period_length_days must be positive.")

    # 1) ë¬´ê²¹ì¹¨ ê°€ëŠ¥ì„± í‰ê°€
    #   d = OOS_Start - IS_Start, ê²¹ì¹¨ = L - d
    #   ë¬´ê²¹ì¹¨ í•„ìš”ì¡°ê±´: d >= L
    #   ê²½ê³„ì¡°ê±´: last_IS_start = E - d - (L-1) >= S  ->  d <= (E - S).days - (L-1)
    Dmax_days = (E - S).days - (L_days - 1)   # dê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœëŒ€ê°’(ê²½ê³„ ìœ„ë°° ì—†ì´)
    d_days = None

    if Dmax_days >= L_days:
        # ì—¬ìœ ë¡œì›€ â†’ ë¬´ê²¹ì¹¨ ì±„íƒ
        d_days = L_days
    else:
        # ì—¬ìœ  ë¶€ì¡± â†’ ê²¹ì¹¨ ìµœì†Œ(= d ìµœëŒ€)ì™€ ê· ë“±ì„±ì˜ ê· í˜•
        # ê¸°ë³¸ê°’: ì ˆë°˜ì¯¤ ì´ë™(ê· í˜•) -> ì´ì „ì— í•©ì˜í•œ dâ‰ˆL/2 (+1 ë³´ì •)
        d_days = min(Dmax_days, (L_days + 1) // 2 + 1)
        if d_days < 1:
            d_days = 1  # ì¸ê³¼ì„± ë³´ì¥

    # 2) ë§ˆì§€ë§‰ í´ë“œê°€ Eì— ë§ë„ë¡ IS ìµœì¢… ì‹œì‘ì  ì—­ì‚°
    d = pd.Timedelta(days=d_days)
    last_is_start = E - d - (L - pd.Timedelta(days=1))

    # 3) IS ì‹œì‘ë“¤ì˜ ê· ë“± ë¶„í¬
    #    span_daysê°€ ì‘ì•„ë„ Nê°œ ê· ë“± ë°°ì¹˜(ì •ìˆ˜ ë³´ì •: ëª«/ë‚˜ë¨¸ì§€ ë°©ì‹)
    span_days = (last_is_start - S).days
    print("span_days:",span_days)
    if span_days <= 0:
        raise ValueError(f"Configuration Error: Cannot fit {N} folds. The total period is too short for the given period length ({L_days} days). Please reduce 'total_folds' or 'period_length_days'.")
    if N == 1:
        is_starts = [S]
    else:
        base_step = span_days // (N - 1)
        remainder = span_days % (N - 1)
        is_starts = [S]
        for i in range(1, N):
            add = base_step + (1 if i <= remainder else 0)
            is_starts.append(is_starts[-1] + pd.Timedelta(days=add))

    # 4) í´ë“œ êµ¬ê°„ êµ¬ì„±
    fold_periods = []
    for i, is_start in enumerate(is_starts):
        is_end   = is_start + L - pd.Timedelta(days=1)
        oos_start = is_start + d
        oos_end   = oos_start + L - pd.Timedelta(days=1)

        # ì•ˆì „ ì²´í¬
        if oos_start < is_start + pd.Timedelta(days=1):
            raise ValueError("Causality violated: OOS must start at least 1 day after IS start.")
        if oos_end > E:
            raise ValueError("Boundary violated: OOS end beyond end_date.")
        if is_start < S or is_end > E:
            raise ValueError("IS period out of bounds.")

        fold_periods.append({
            'Fold': i + 1,
            'IS_Start': is_start.date(), 'IS_End': is_end.date(),
            'OOS_Start': oos_start.date(), 'OOS_End': oos_end.date()
        })

    print("\n--- Calculated Walk-Forward Folds ---")
    print(pd.DataFrame(fold_periods).to_string(index=False))

    # ì°¸ê³  ì¶œë ¥(ì„ íƒ): ì‹¤ì œ ê²¹ì¹¨ì¼
    overlap_days = L_days - d_days  # (0ì´ë©´ ë¬´ê²¹ì¹¨)
    print(f"\n[WFO] d = {d_days} days â†’ overlap = {overlap_days} days (per fold)")


    
    #  ìƒˆë¡œìš´ ë¡¤ë§ ìœˆë„ìš° ë£¨í”„
    all_oos_curves, all_optimal_params = [], []
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_dir = os.path.join("results", f"wfo_run_{timestamp}")
    os.makedirs(results_dir, exist_ok=True)
    
    pbar = tqdm(fold_periods, desc="WFO Progress")
    for period in pbar:
        fold_num, is_start, is_end, oos_start, oos_end = period.values()
        pbar.set_description(f"WFO Fold {fold_num}/{total_folds}")

        print(f"\n--- Fold {fold_num} IS Period: {is_start} ~ {is_end} ---")
        
        # [MODIFIED] 1. IS ê¸°ê°„ì˜ "ì „ì²´" ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ í™•ë³´
        _, is_simulation_results_df = find_optimal_parameters(
             start_date=is_start.strftime('%Y-%m-%d'),
             end_date=is_end.strftime('%Y-%m-%d'),
             initial_cash=initial_cash
         )
        print(f"  - IS simulation complete. Analyzing {len(is_simulation_results_df)} combinations.")
        
        # [NEW] 2. í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ê°•ê±´ íŒŒë¼ë¯¸í„° íƒìƒ‰
        robust_params_dict, clustered_df = find_robust_parameters(
            simulation_results_df=is_simulation_results_df,
            param_cols=['additional_buy_drop_rate', 'sell_profit_rate', 'stop_loss_rate', 'max_inactivity_period'],
            metric_cols=['cagr', 'mdd', 'calmar_ratio'],
            k_range=(2, 8),
            min_cluster_size_ratio=0.05
        )
        
        # ë””ë²„ê¹…ì„ ìœ„í•´ ê° í´ë“œì˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì €ì¥
        if clustered_df is not None:
            fold_cluster_path = os.path.join(results_dir, f"fold_{fold_num}_clustered_results.csv")
            clustered_df.to_csv(fold_cluster_path, index=False)
            print(f"  - Fold {fold_num} clustered analysis saved.")

        robust_params_dict['fold'] = fold_num
        all_optimal_params.append(robust_params_dict)
        print(f"  - Robust params for Fold {fold_num} selected.")
        
        if total_folds == 1:
            print("\n[INFO] Single fold run. OOS performance is same as IS robust parameter performance.")
            # ë‹¨ì¼ í´ë“œì—ì„œëŠ” OOS ì»¤ë¸Œê°€ ì˜ë¯¸ ì—†ìœ¼ë¯€ë¡œ IS ê²°ê³¼ë¥¼ ì‚¬ìš© (í˜¹ì€ ìƒëµ)
            break

        print(f"--- Fold {fold_num} OOS Period: {oos_start} ~ {oos_end} ---")
        
        # 3. ì°¾ì€ íŒŒë¼ë¯¸í„°ë¡œ OOS ê¸°ê°„ ë°±í…ŒìŠ¤íŠ¸
        # OOS ê¸°ê°„ì˜ ì´ˆê¸° ìê¸ˆì€ ì´ì „ OOS ê¸°ê°„ì˜ ìµœì¢… ìê¸ˆìœ¼ë¡œ ì—°ê²°
        oos_equity_curve = run_single_backtest(
             start_date=oos_start.strftime('%Y-%m-%d'),
             end_date=oos_end.strftime('%Y-%m-%d'),
             params_dict=robust_params_dict,
             initial_cash=initial_cash if not all_oos_curves else all_oos_curves[-1].iloc[-1]
         )
        all_oos_curves.append(oos_equity_curve)    
            
    pbar.close()

    # 5. [ìˆ˜ì •] ìµœì¢… ê²°ê³¼ ì¢…í•© ë° ë¶„ì„ (ê³ ë„í™”)
    print("\n" + "="*80)
    print("ğŸ“ˆ Walk-Forward Analysis Finished. Aggregating results...")
    print("="*80)

    if not all_oos_curves:
        print("[ERROR] No Out-of-Sample results were generated.")
        # ë‹¨ì¼ í´ë“œ ì‹¤í–‰ ì‹œ ì—¬ê¸°ë¡œ ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, íŒŒë¼ë¯¸í„° ë¶„ì„ë§Œ ìˆ˜í–‰
    else:
        final_wfo_curve = pd.concat(all_oos_curves).sort_index().groupby(level=0).mean()
        wfo_analyzer = PerformanceAnalyzer(pd.DataFrame(final_wfo_curve, columns=['total_value']))
        
        print("\n--- Final WFO Performance Metrics ---")
        for key, value in wfo_analyzer.get_metrics(formatted=True).items():
            print(f"  {key:<25}: {value}")
        
        curve_filepath = os.path.join(results_dir, "wfo_equity_curve_data.csv")
        final_wfo_curve.to_csv(curve_filepath)
        print(f"\nâœ… Final WFO equity curve data saved to: {curve_filepath}")
        plot_wfo_results(final_wfo_curve, pd.DataFrame(all_optimal_params), results_dir)

   
   
    # 5-2. íŒŒë¼ë¯¸í„° ì•ˆì •ì„± ë¶„ì„ ë° ê²°ê³¼ ì €ì¥
    params_df = pd.DataFrame(all_optimal_params)
    print("\nğŸ“Š Optimal Parameter Stability Analysis (Descriptive Stats):")
    # ë¬¸ìì—´ íƒ€ì… íŒŒë¼ë¯¸í„°ëŠ” ì œì™¸í•˜ê³  ê¸°ìˆ  í†µê³„ ì¶œë ¥
    print(params_df.drop(columns=['additional_buy_priority'], errors='ignore').describe())
    
    params_filepath = os.path.join(results_dir, "wfo_robust_parameters.csv")
    params_df.to_csv(params_filepath, index=False)
   
    print(f"\nâœ… Robust parameters for each fold saved to: {params_filepath}")

if __name__ == '__main__':
    run_walk_forward_analysis()
