"""
This script is used to debug the GPU single run.
It is used to test the GPU single run with the parameters from the config.yaml file.
"""
import time
import cudf
import cupy as cp
import pandas as pd
from sqlalchemy import create_engine
from datetime import timedelta, datetime # datetime ì¶”ê°€
import os
import urllib.parse

# --- í•„ìš”í•œ ëª¨ë“ˆ ì¶”ê°€ ì„í¬íŠ¸ ---
from src.config_loader import load_config
from src.backtest_strategy_gpu import run_magic_split_strategy_on_gpu
### ì´ìŠˆ #3 ë™ê¸°í™”ë¥¼ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸ ###
from src.performance_analyzer import PerformanceAnalyzer

# -----------------------------------------------------------------------------
# 1. Configuration and Parameter Setup
# -----------------------------------------------------------------------------

# --- ì„¤ì • íŒŒì¼ ë¡œë“œ (YAML ë¡œë”ë¡œ í†µì¼) ---
config = load_config()
db_config = config['database']
backtest_settings = config['backtest_settings']
strategy_params = config['strategy_params']
execution_params = config['execution_params']

# GPU ì»¤ë„ì— ì¿¨ë‹¤ìš´ ê¸°ê°„ ì „ë‹¬ì„ ìœ„í•´ execution_paramsì— ì¶”ê°€
execution_params['cooldown_period_days'] = strategy_params.get('cooldown_period_days', 5)

# URL ì¸ì½”ë”©ì„ í¬í•¨í•˜ì—¬ DB ì—°ê²° ë¬¸ìì—´ ìƒì„±
db_pass_encoded = urllib.parse.quote_plus(db_config['password'])
db_connection_str = (
    f"mysql+pymysql://{db_config['user']}:{db_pass_encoded}"
    f"@{db_config['host']}/{db_config['database']}"
)

# --- Debugë¥¼ ìœ„í•œ ë‹¨ì¼ íŒŒë¼ë¯¸í„° ì¡°í•© ì •ì˜ ---
cpu_test_params = config['strategy_params']
max_stocks_options = cp.array([cpu_test_params['max_stocks']], dtype=cp.int32)
order_investment_ratio_options = cp.array([cpu_test_params['order_investment_ratio']], dtype=cp.float32)
additional_buy_drop_rate_options = cp.array([cpu_test_params['additional_buy_drop_rate']], dtype=cp.float32)
sell_profit_rate_options = cp.array([cpu_test_params['sell_profit_rate']], dtype=cp.float32)

priority_map = {'lowest_order': 0, 'highest_drop': 1}
priority_val = priority_map.get(cpu_test_params['additional_buy_priority'], 0)
additional_buy_priority_options = cp.array([priority_val], dtype=cp.int32)

# --- [New] Load Advanced Risk Management Parameters ---
stop_loss_rate_options = cp.array([cpu_test_params.get('stop_loss_rate', -0.15)], dtype=cp.float32)
max_splits_limit_options = cp.array([cpu_test_params.get('max_splits_limit', 10)], dtype=cp.int32)
max_inactivity_period_options = cp.array([cpu_test_params.get('max_inactivity_period', 90)], dtype=cp.int32)


grid = cp.meshgrid(
    max_stocks_options,
    order_investment_ratio_options,
    additional_buy_drop_rate_options,
    sell_profit_rate_options,
    additional_buy_priority_options,
    stop_loss_rate_options,          
    max_splits_limit_options,        
    max_inactivity_period_options       
)
param_combinations = cp.vstack([item.flatten() for item in grid]).T
num_combinations = param_combinations.shape[0]

print("âœ… [DEBUG MODE] Single parameter combination for GPU test:")
print(param_combinations.get())
print(f"âœ… Total parameter combinations generated for GPU: {num_combinations}")


# -----------------------------------------------------------------------------
# 2. GPU Data Pre-loader
# -----------------------------------------------------------------------------

def preload_all_data_to_gpu(engine, start_date, end_date):
    """
    Loads all necessary stock data for the entire backtest period into a
    single cuDF DataFrame.
    """
    print("â³ Loading all stock data into GPU memory...")
    start_time = time.time()
    
    query = f"""
    SELECT 
        dsp.stock_code AS ticker, 
        dsp.date, 
        dsp.open_price, 
        dsp.high_price, 
        dsp.low_price, 
        dsp.close_price, 
        dsp.volume,
        ci.atr_14_ratio
    FROM 
        DailyStockPrice AS dsp
    LEFT JOIN 
        CalculatedIndicators AS ci ON dsp.stock_code = ci.stock_code AND dsp.date = ci.date
    WHERE 
        dsp.date BETWEEN '{start_date}' AND '{end_date}'
    """
    sql_engine = create_engine(engine)
    df_pd = pd.read_sql(query, sql_engine, parse_dates=['date'])
    gdf = cudf.from_pandas(df_pd)
    gdf = gdf.set_index(['ticker', 'date'])
    
    end_time = time.time()
    print(f"âœ… Data loaded to GPU. Shape: {gdf.shape}. Time: {end_time - start_time:.2f}s")
    return gdf

def preload_weekly_filtered_stocks_to_gpu(engine, start_date, end_date):
    """
    Loads all weekly filtered stock codes for the backtest period.
    """
    print("â³ Loading weekly filtered stocks data to GPU memory...")
    start_time = time.time()
    
    extended_start_date = pd.to_datetime(start_date) - timedelta(days=14)
    extended_start_date_str = extended_start_date.strftime('%Y-%m-%d')
    
    query =  f"""
    SELECT `filter_date` as date, `stock_code` as ticker
    FROM WeeklyFilteredStocks
    WHERE `filter_date` BETWEEN '{extended_start_date_str}' AND '{end_date}'
    """
    sql_engine = create_engine(engine)
    df_pd = pd.read_sql(query, sql_engine, parse_dates=['date'])
    gdf = cudf.from_pandas(df_pd)
    gdf = gdf.set_index('date')
    
    end_time = time.time()
    print(f"âœ… Weekly filtered stocks loaded to GPU. Shape: {gdf.shape}. Time: {end_time - start_time:.2f}s")
    return gdf

def preload_tier_data_to_tensor(engine, start_date, end_date, all_tickers, trading_dates_pd):
    """
    Loads DailyStockTier data and converts it to a dense (num_days, num_tickers) int8 tensor.
    Performs forward-fill to ensure PIT compliance (latest <= date).
    """
    print("â³ Loading DailyStockTier data to GPU tensor...")
    start_time = time.time()
    
    start_date_str = pd.to_datetime(start_date).strftime('%Y-%m-%d')
    end_date_str = pd.to_datetime(end_date).strftime('%Y-%m-%d')
    query = f"""
        SELECT date, stock_code as ticker, tier
        FROM DailyStockTier
        WHERE date BETWEEN '{start_date_str}' AND '{end_date_str}'
        UNION ALL
        SELECT t.date, t.stock_code as ticker, t.tier
        FROM DailyStockTier t
        JOIN (
            SELECT stock_code, MAX(date) AS max_date
            FROM DailyStockTier
            WHERE date < '{start_date_str}'
            GROUP BY stock_code
        ) latest ON t.stock_code = latest.stock_code AND t.date = latest.max_date
    """
    sql_engine = create_engine(engine)
    df_pd = pd.read_sql(query, sql_engine, parse_dates=['date'])
    
    if df_pd.empty:
        print("âš ï¸ No Tier data found. Returning empty tensor.")
        return cp.zeros((len(trading_dates_pd), len(all_tickers)), dtype=cp.int8)

    # Pivot to (date, ticker) -> tier
    # index=date, columns=ticker, values=tier
    df_wide = df_pd.pivot_table(index='date', columns='ticker', values='tier')
    
    # Reindex to full trading dates and all tickers
    # Forward fill to propagate the latest tier
    df_reindexed = df_wide.reindex(index=trading_dates_pd, columns=all_tickers).ffill().fillna(0).astype(int)
    
    # Convert to CuPy
    tier_tensor = cp.asarray(df_reindexed.values, dtype=cp.int8)
    
    print(f"âœ… Tier data loaded and tensorized. Shape: {tier_tensor.shape}. Time: {time.time() - start_time:.2f}s")
    return tier_tensor

# -----------------------------------------------------------------------------
# 3. GPU Backtesting Kernel
# -----------------------------------------------------------------------------

def run_gpu_backtest_kernel(params_gpu, data_gpu,
                         weekly_filtered_gpu, all_tickers,
                         trading_date_indices_gpu,
                         trading_dates_pd,
                         initial_cash_value,
                         exec_params: dict,
                         debug_mode: bool = False,
                         tier_tensor: cp.ndarray = None # [Issue #67]
                         ):
    """
    GPU-accelerated ë°±í…ŒìŠ¤íŒ… ì»¤ë„ì„ ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print("ğŸš€ Starting GPU backtesting kernel...")
    
    daily_portfolio_values = run_magic_split_strategy_on_gpu(
        initial_cash=initial_cash_value,
        param_combinations=params_gpu,
        all_data_gpu=data_gpu,
        weekly_filtered_gpu=weekly_filtered_gpu,
        trading_date_indices=trading_date_indices_gpu,
        trading_dates_pd_cpu=trading_dates_pd,
        all_tickers=all_tickers,
        max_splits_limit=20,
        execution_params=exec_params,
        debug_mode=debug_mode,
        tier_tensor=tier_tensor
    )
    
    print("ğŸ‰ GPU backtesting kernel finished.")
    
    return daily_portfolio_values

# 4. [ì‹ ê·œ] ì›Œì»¤ í•¨ìˆ˜: run_single_backtest
def run_single_backtest(start_date: str, end_date: str, params_dict: dict, initial_cash: float, debug_mode: bool = False):
    """
    ì£¼ì–´ì§„ ê¸°ê°„ê³¼ íŒŒë¼ë¯¸í„°ë¡œ ë‹¨ì¼ GPU ë°±í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    WFO ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì— ì˜í•´ í˜¸ì¶œë˜ëŠ” 'ì›Œì»¤' í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    print(f"\n" + "="*80)
    print(f"WORKER: Running Single Backtest for {start_date} to {end_date}")
    print(f"Params: {params_dict}")
    print("="*80)

    # 1. íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ë¥¼ GPUê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” cp.ndarrayë¡œ ë³€í™˜
    priority_map = {'lowest_order': 0, 'highest_drop': 1}
    priority_val = priority_map.get(params_dict.get('additional_buy_priority', 'lowest_order'), 0)
    
    param_combinations = cp.array([[
        params_dict['max_stocks'],
        params_dict['order_investment_ratio'],
        params_dict['additional_buy_drop_rate'],
        params_dict['sell_profit_rate'],
        priority_val,
        params_dict['stop_loss_rate'],
        params_dict['max_splits_limit'],
        params_dict['max_inactivity_period'],
    ]], dtype=cp.float32)

    # 2. ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„
    all_data_gpu = preload_all_data_to_gpu(db_connection_str, start_date, end_date)
    weekly_filtered_gpu = preload_weekly_filtered_stocks_to_gpu(db_connection_str, start_date, end_date)
    
    sql_engine = create_engine(db_connection_str)
    trading_dates_query = f"""
        SELECT DISTINCT date 
        FROM DailyStockPrice 
        WHERE date BETWEEN '{start_date}' AND '{end_date}'
        ORDER BY date
    """
    trading_dates_pd_df = pd.read_sql(trading_dates_query, sql_engine, parse_dates=['date'], index_col='date')
    trading_dates_pd = trading_dates_pd_df.index # ì´ì œ DatetimeIndex ê°ì²´
    trading_date_indices_gpu = cp.arange(len(trading_dates_pd), dtype=cp.int32)
    
    all_data_gpu = all_data_gpu[all_data_gpu.index.get_level_values('date').isin(trading_dates_pd)]
    all_tickers = sorted(all_data_gpu.index.get_level_values('ticker').unique().to_pandas().tolist())
    print(f"  - Tickers for period: {len(all_tickers)}")
    print(f"  - Trading days for period: {len(trading_dates_pd)}")

    # [Issue #67] Preload Tier Tensor
    tier_tensor = preload_tier_data_to_tensor(db_connection_str, start_date, end_date, all_tickers, trading_dates_pd)

    # 3. ë°±í…ŒìŠ¤íŒ… ì»¤ë„ ì‹¤í–‰
    start_time_kernel = time.time()
    
    # exec_paramsì— ëª¨ë“œ ì •ë³´ ì¶”ê°€
    execution_params = execution_params.copy()
    execution_params['candidate_source_mode'] = params_dict.get('candidate_source_mode', 'weekly')
    execution_params['use_weekly_alpha_gate'] = params_dict.get('use_weekly_alpha_gate', False)
    
    daily_values_result = run_gpu_backtest_kernel(
        param_combinations, 
        all_data_gpu, 
        weekly_filtered_gpu,
        all_tickers, 
        trading_date_indices_gpu,
        trading_dates_pd,
        initial_cash,
        execution_params,
        debug_mode=debug_mode,
        tier_tensor=tier_tensor
    )
    end_time_kernel = time.time()
    print(f"  - GPU Kernel Execution Time: {end_time_kernel - start_time_kernel:.2f}s")
    
    # 4. ê²°ê³¼ ì²˜ë¦¬ ë° ë°˜í™˜
    if daily_values_result is None or daily_values_result.shape[0] == 0:
        print("  - [Warning] Backtest returned no data. Returning empty series.")
        return pd.Series(dtype=float)

    daily_values_cpu = daily_values_result.get()[0] # ì²« ë²ˆì§¸ (ìœ ì¼í•œ) ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
    equity_curve_series = pd.Series(daily_values_cpu, index=trading_dates_pd)
    
    return equity_curve_series
# -----------------------------------------------------------------------------
# 5. Main Execution Block
# -----------------------------------------------------------------------------

if __name__ == "__main__":
    # ì´ íŒŒì¼ì´ ë‹¨ë…ìœ¼ë¡œ ì‹¤í–‰ë  ë•Œ, config.yamlì˜ ì„¤ì •ìœ¼ë¡œ CPU-GPU ë¹„êµ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    backtest_start_date = backtest_settings['start_date']
    backtest_end_date = backtest_settings['end_date']
    initial_cash = backtest_settings['initial_cash']
    
    print(f"ğŸ“… Running Standalone GPU Debug/Verification Run")
    print(f"ğŸ“… Period: {backtest_start_date} ~ {backtest_end_date}")
    # config.yamlì—ì„œ ì§ì ‘ íŒŒë¼ë¯¸í„° ë¡œë“œ
    params_for_debug = config['strategy_params']
    
    # ë¦¬íŒ©í† ë§ëœ ì›Œì»¤ í•¨ìˆ˜ í˜¸ì¶œ
    equity_curve = run_single_backtest(
        start_date=backtest_start_date,
        end_date=backtest_end_date,
        params_dict=params_for_debug,
        initial_cash=initial_cash,
        debug_mode=True  # ë‹¨ë… ì‹¤í–‰ ì‹œì—ëŠ” í•­ìƒ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
    )
    
    # ê¸°ì¡´ê³¼ ë™ì¼í•œ ì„±ê³¼ ë¶„ì„ ë° ì¶œë ¥ ë¡œì§
    print("\n" + "="*60)
    print("ğŸ“ˆ GPU Standalone Run - Performance Summary")
    print("="*60)
    

    if not equity_curve.empty:
        history_df = pd.DataFrame(equity_curve, columns=['total_value'])
        analyzer = PerformanceAnalyzer(history_df)
        metrics = analyzer.get_metrics(formatted=True)

        for key, value in metrics.items():
            print(f"{key:<25}: {value}")
    else:
        print("Error: No backtesting result data to analyze.")

    print("="*60)
    print(f"\nâœ… GPU standalone run and analysis complete!")
