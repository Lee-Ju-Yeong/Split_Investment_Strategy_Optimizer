{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3409f4f2-2450-46bc-91e2-e4e154c554e6",
   "metadata": {},
   "source": [
    "# 주식 및 ETF 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a838f83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pykrx in e:\\아경\\ai\\python38\\lib\\site-packages (1.0.45)\n",
      "Collecting pykrx\n",
      "  Downloading pykrx-1.0.48-py3-none-any.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.9/60.9 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (2.32.3)\n",
      "Requirement already satisfied: pandas in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (1.5.3)\n",
      "Requirement already satisfied: datetime in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (5.5)\n",
      "Requirement already satisfied: numpy in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (1.24.4)\n",
      "Requirement already satisfied: xlrd in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (2.0.1)\n",
      "Requirement already satisfied: deprecated in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (1.2.14)\n",
      "Requirement already satisfied: multipledispatch in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in e:\\아경\\ai\\python38\\lib\\site-packages (from pykrx) (3.6.0)\n",
      "Requirement already satisfied: zope.interface in e:\\아경\\ai\\python38\\lib\\site-packages (from datetime->pykrx) (6.4.post2)\n",
      "Requirement already satisfied: pytz in e:\\아경\\ai\\python38\\lib\\site-packages (from datetime->pykrx) (2023.3.post1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\아경\\ai\\python38\\lib\\site-packages (from deprecated->pykrx) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\아경\\ai\\python38\\lib\\site-packages (from matplotlib->pykrx) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\아경\\ai\\python38\\lib\\site-packages (from requests->pykrx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\아경\\ai\\python38\\lib\\site-packages (from requests->pykrx) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\아경\\ai\\python38\\lib\\site-packages (from requests->pykrx) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\아경\\ai\\python38\\lib\\site-packages (from requests->pykrx) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.5 in e:\\아경\\ai\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pykrx) (1.16.0)\n",
      "Requirement already satisfied: setuptools in e:\\아경\\ai\\python38\\lib\\site-packages (from zope.interface->datetime->pykrx) (49.2.1)\n",
      "Downloading pykrx-1.0.48-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.6/2.2 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 10.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pykrx\n",
      "  Attempting uninstall: pykrx\n",
      "    Found existing installation: pykrx 1.0.45\n",
      "    Uninstalling pykrx-1.0.45:\n",
      "      Successfully uninstalled pykrx-1.0.45\n",
      "Successfully installed pykrx-1.0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pykrx\n",
    "# pip install/ beautifulsoup4 pandas openpyxl selenium webdriver-manager pykrx sqlalchemy pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31315c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: configparser in e:\\아경\\ai\\python38\\lib\\site-packages (7.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install configparser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed37cfd1-8643-468d-b27a-8dc573731d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.ini 파일을 찾았습니다.\n",
      "Username: root, Password: @waren2ss, Host: 127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "from pykrx import stock\n",
    "import datetime\n",
    "import os\n",
    "# from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import configparser\n",
    "\n",
    "import os\n",
    "\n",
    "# ConfigParser 객체 생성\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# config.ini 파일 경로 설정\n",
    "config_file_path = 'E:\\\\AI\\\\pythonProject\\\\venv\\\\masicsplit\\\\config.ini'\n",
    "\n",
    "# 경로가 올바른지 확인\n",
    "if os.path.exists(config_file_path):\n",
    "    print(\"config.ini 파일을 찾았습니다.\")\n",
    "    config.read(config_file_path)\n",
    "else:\n",
    "    print(\"config.ini 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "\n",
    "# mysql 섹션에서 설정값 가져오기\n",
    "try:\n",
    "    username = config['mysql']['user']\n",
    "    password = config['mysql']['password']\n",
    "    host = config['mysql']['host']\n",
    "    database=config['mysql']['database']\n",
    "    print(f\"Username: {username}, Password: {password}, Host: {host}\")\n",
    "except KeyError as e:\n",
    "    print(f\"설정 파일에서 키를 찾을 수 없습니다: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"기타 오류 발생: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2acfc",
   "metadata": {},
   "source": [
    "# 주식 및 ETF 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e928c54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cur' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     26\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m    CREATE TABLE IF NOT EXISTS ticker_list (\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m        ticker VARCHAR(10) PRIMARY KEY,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m    )\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     35\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m    CREATE TABLE IF NOT EXISTS ticker_status (\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124m        ticker VARCHAR(10) PRIMARY KEY,\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124m        status VARCHAR(20)\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124m    )\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[43mcreate_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m, in \u001b[0;36mcreate_tables\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_tables\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    CREATE TABLE IF NOT EXISTS stock_data (\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m        ticker VARCHAR(10),\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m        name VARCHAR(100),\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m        date DATE,\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m        open FLOAT,\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m        high FLOAT,\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m        low FLOAT,\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124m        close FLOAT,\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m        volume BIGINT,\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m        value BIGINT,\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m        market_cap BIGINT,\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m        shares_outstanding BIGINT,\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m        PER FLOAT,\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m        PBR FLOAT,\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m        dividend FLOAT,\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124m        BPS FLOAT,\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m        EPS FLOAT,\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m        DPS FLOAT,\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124m        normalized_value FLOAT,\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m        PRIMARY KEY (ticker, date)\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124m    )\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     26\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m    CREATE TABLE IF NOT EXISTS ticker_list (\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124m        ticker VARCHAR(10) PRIMARY KEY,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124m    )\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     35\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m    CREATE TABLE IF NOT EXISTS ticker_status (\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124m        ticker VARCHAR(10) PRIMARY KEY,\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124m        status VARCHAR(20)\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124m    )\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cur' is not defined"
     ]
    }
   ],
   "source": [
    "# 테이블 생성 함수\n",
    "def create_tables():\n",
    "    cur.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS stock_data (\n",
    "        ticker VARCHAR(10),\n",
    "        name VARCHAR(100),\n",
    "        date DATE,\n",
    "        open FLOAT,\n",
    "        high FLOAT,\n",
    "        low FLOAT,\n",
    "        close FLOAT,\n",
    "        volume BIGINT,\n",
    "        value BIGINT,\n",
    "        market_cap BIGINT,\n",
    "        shares_outstanding BIGINT,\n",
    "        PER FLOAT,\n",
    "        PBR FLOAT,\n",
    "        dividend FLOAT,\n",
    "        BPS FLOAT,\n",
    "        EPS FLOAT,\n",
    "        DPS FLOAT,\n",
    "        normalized_value FLOAT,\n",
    "        PRIMARY KEY (ticker, date)\n",
    "    )\n",
    "    ''')\n",
    "    cur.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS ticker_list (\n",
    "        ticker VARCHAR(10) PRIMARY KEY,\n",
    "        market VARCHAR(10),\n",
    "        name VARCHAR(100),\n",
    "        last_updated DATE,\n",
    "        is_delisted BOOLEAN DEFAULT FALSE\n",
    "    )\n",
    "    ''')\n",
    "    cur.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS ticker_status (\n",
    "        ticker VARCHAR(10) PRIMARY KEY,\n",
    "        status VARCHAR(20)\n",
    "    )\n",
    "    ''')\n",
    "create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e8fc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19950102\n",
      "956 19950701\n",
      "1132 19951228\n",
      "1190 19960625\n",
      "1758 19961222\n",
      "1827 19970620\n",
      "1906 19971217\n",
      "1930 19980615\n",
      "1941 19981212\n",
      "2003 19990610\n",
      "2117 19991207\n",
      "2298 20000604\n",
      "2440 20001201\n",
      "2525 20010530\n",
      "2638 20011126\n",
      "2773 20020525\n",
      "2848 20021121\n",
      "2895 20030520\n",
      "2944 20031116\n",
      "2983 20040514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     all_tickers\u001b[38;5;241m.\u001b[39mupdate(tickers_kospi)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_tickers), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on date \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모든 티커 리스트를 저장할 집합\n",
    "all_tickers = set()\n",
    "\n",
    "# 시작 날짜와 현재 날짜 설정\n",
    "start_date = '19950102' # 이 시기부터 ticker list를 제공\n",
    "end_date = datetime.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "# 모든 날짜에 대해 티커 리스트 가져오기\n",
    "current_date = datetime.datetime.strptime(start_date, '%Y%m%d')\n",
    "while current_date.strftime('%Y%m%d') <= end_date:\n",
    "    date_str = current_date.strftime('%Y%m%d')\n",
    "    try:\n",
    "        tickers_kosdaq = stock.get_market_ticker_list(date_str, market='KOSDAQ')\n",
    "        tickers_kospi = stock.get_market_ticker_list(date_str, market='KOSPI')\n",
    "        all_tickers.update(tickers_kosdaq)\n",
    "        all_tickers.update(tickers_kospi)\n",
    "        print(len(all_tickers), f'{date_str}')\n",
    "        time.sleep(0.8)\n",
    "    except Exception as e:\n",
    "        print(f\"Error on date {date_str}: {e}\")\n",
    "    current_date += datetime.timedelta(days=180)  # 180일 단위로 진행\n",
    "\n",
    "conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 티커 목록을 MySQL에 저장\n",
    "for ticker in all_tickers:\n",
    "    market = 'KOSDAQ' if ticker in tickers_kosdaq else 'KOSPI'\n",
    "    name = stock.get_market_ticker_name(ticker)\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute('''\n",
    "            INSERT INTO ticker_list (ticker, market, name) VALUES (%s, %s, %s)\n",
    "            ON DUPLICATE KEY UPDATE market=VALUES(market), name=VALUES(name)\n",
    "            ''', (ticker, market, name))\n",
    "            \n",
    "            # cur.execute('''\n",
    "            # INSERT INTO ticker_status (ticker, status) VALUES (%s, 'pending')\n",
    "            # ON DUPLICATE KEY UPDATE status=VALUES(status)\n",
    "            # ''', (ticker,))\n",
    "            conn.commit()\n",
    "    except pymysql.InterfaceError as e:\n",
    "        print(f\"InterfaceError: {e}, reconnecting...\")\n",
    "        conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8') # 재연결 시도\n",
    "    except pymysql.DatabaseError as e:\n",
    "        print(f\"DatabaseError: {e}\")\n",
    "        conn.rollback()  # 롤백하여 데이터 일관성 유지\n",
    "\n",
    "conn.close()\n",
    "print(\"모든 티커 목록이 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419ab92",
   "metadata": {},
   "source": [
    "## Step 2: 데이터 갱신 및 새로운 티커 추가 (중단 후 재시작 가능)\n",
    "* 한번 실행한 경우 몇 거래일 뒤에 다시 실행해야 오류가 발생하지 않음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aab686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.ini 파일을 찾았습니다.\n",
      "000040 already done\n",
      "000050 already done\n",
      "000070 already done\n",
      "000080 already done\n",
      "000100 already done\n",
      "000120 already done\n",
      "000140 already done\n",
      "000150 already done\n",
      "000180 already done\n",
      "000210 already done\n",
      "000220 already done\n",
      "000230 already done\n",
      "000240 already done\n",
      "000250 already done\n",
      "000270 already done\n",
      "000300 already done\n",
      "000320 already done\n",
      "000370 already done\n",
      "000390 already done\n",
      "000400 already done\n",
      "000430 already done\n",
      "000440 already done\n",
      "000480 already done\n",
      "000490 already done\n",
      "000500 already done\n",
      "000520 already done\n",
      "000540 already done\n",
      "000590 already done\n",
      "000640 already done\n",
      "000650 already done\n",
      "000660 already done\n",
      "000670 already done\n",
      "000680 already done\n",
      "000700 already done\n",
      "000720 already done\n",
      "000760 already done\n",
      "000810 already done\n",
      "000850 already done\n",
      "000860 already done\n",
      "000880 already done\n",
      "000890 already done\n",
      "000910 already done\n",
      "000950 already done\n",
      "000970 already done\n",
      "000990 already done\n",
      "001000 already done\n",
      "001020 already done\n",
      "001040 already done\n",
      "001060 already done\n",
      "001070 already done\n",
      "001080 already done\n",
      "001120 already done\n",
      "001130 already done\n",
      "001140 already done\n",
      "001200 already done\n",
      "001210 already done\n",
      "001230 already done\n",
      "001250 already done\n",
      "001260 already done\n",
      "001270 already done\n",
      "001290 already done\n",
      "001340 already done\n",
      "001360 already done\n",
      "001380 already done\n",
      "001390 already done\n",
      "001420 already done\n",
      "001430 already done\n",
      "001440 already done\n",
      "001450 already done\n",
      "001460 already done\n",
      "001470 already done\n",
      "001500 already done\n",
      "001510 already done\n",
      "001520 already done\n",
      "001530 already done\n",
      "001540 already done\n",
      "001550 already done\n",
      "001560 already done\n",
      "001570 already done\n",
      "001620 already done\n",
      "001630 already done\n",
      "001680 already done\n",
      "001720 already done\n",
      "001740 already done\n",
      "001750 already done\n",
      "001770 already done\n",
      "001780 already done\n",
      "001790 already done\n",
      "001800 already done\n",
      "001810 already done\n",
      "001820 already done\n",
      "001840 already done\n",
      "001940 already done\n",
      "002020 already done\n",
      "002030 already done\n",
      "002070 already done\n",
      "002100 already done\n",
      "002140 already done\n",
      "002150 already done\n",
      "002170 already done\n",
      "002200 already done\n",
      "002210 already done\n",
      "002220 already done\n",
      "002230 already done\n",
      "002240 already done\n",
      "002290 already done\n",
      "002310 already done\n",
      "002320 already done\n",
      "002350 already done\n",
      "002360 already done\n",
      "002380 already done\n",
      "002390 already done\n",
      "002410 already done\n",
      "002420 already done\n",
      "002450 already done\n",
      "002460 already done\n",
      "002600 already done\n",
      "002620 already done\n",
      "002630 already done\n",
      "002680 already done\n",
      "002690 already done\n",
      "002700 already done\n",
      "002710 already done\n",
      "002720 already done\n",
      "002760 already done\n",
      "002780 already done\n",
      "002790 already done\n",
      "002800 already done\n",
      "002810 already done\n",
      "002820 already done\n",
      "002840 already done\n",
      "002870 already done\n",
      "002880 already done\n",
      "002900 already done\n",
      "002920 already done\n",
      "002960 already done\n",
      "002990 already done\n",
      "003000 already done\n",
      "003010 already done\n",
      "003030 already done\n",
      "003060 already done\n",
      "003070 already done\n",
      "003080 already done\n",
      "003090 already done\n",
      "003100 already done\n",
      "003120 already done\n",
      "003160 already done\n",
      "003200 already done\n",
      "003220 already done\n",
      "003230 already done\n",
      "003240 already done\n",
      "003280 already done\n",
      "003300 already done\n",
      "003310 already done\n",
      "003350 already done\n",
      "003380 already done\n",
      "003460 already done\n",
      "003470 already done\n",
      "003480 already done\n",
      "003490 already done\n",
      "003520 already done\n",
      "003530 already done\n",
      "003540 already done\n",
      "003550 already done\n",
      "003560 already done\n",
      "003570 already done\n",
      "003580 already done\n",
      "003610 already done\n",
      "003620 already done\n",
      "003650 already done\n",
      "003670 already done\n",
      "003680 already done\n",
      "003690 already done\n",
      "003720 already done\n",
      "003780 already done\n",
      "003800 already done\n",
      "003830 already done\n",
      "003850 already done\n",
      "003920 already done\n",
      "003960 already done\n",
      "004000 already done\n",
      "004020 already done\n",
      "004060 already done\n",
      "004080 already done\n",
      "004090 already done\n",
      "004100 already done\n",
      "004140 already done\n",
      "004150 already done\n",
      "004170 already done\n",
      "004250 already done\n",
      "004270 already done\n",
      "004310 already done\n",
      "004360 already done\n",
      "004370 already done\n",
      "004380 already done\n",
      "004410 already done\n",
      "004430 already done\n",
      "004440 already done\n",
      "004450 already done\n",
      "004490 already done\n",
      "004540 already done\n",
      "004560 already done\n",
      "004590 already done\n",
      "004650 already done\n",
      "004690 already done\n",
      "004700 already done\n",
      "004710 already done\n",
      "004720 already done\n",
      "004770 already done\n",
      "004780 already done\n",
      "004800 already done\n",
      "004830 already done\n",
      "004840 already done\n",
      "004870 already done\n",
      "004890 already done\n",
      "004910 already done\n",
      "004920 already done\n",
      "004960 already done\n",
      "004970 already done\n",
      "004980 already done\n",
      "004990 already done\n",
      "005010 already done\n",
      "005030 already done\n",
      "005070 already done\n",
      "005090 already done\n",
      "005110 already done\n",
      "005160 already done\n",
      "005180 already done\n",
      "005250 already done\n",
      "005290 already done\n",
      "005300 already done\n",
      "005320 already done\n",
      "005360 already done\n",
      "005380 already done\n",
      "005390 already done\n",
      "005420 already done\n",
      "005430 already done\n",
      "005440 already done\n",
      "005490 already done\n",
      "005500 already done\n",
      "005610 already done\n",
      "005670 already done\n",
      "005680 already done\n",
      "005690 already done\n",
      "005710 already done\n",
      "005720 already done\n",
      "005740 already done\n",
      "005750 already done\n",
      "005800 already done\n",
      "005810 already done\n",
      "005820 already done\n",
      "005830 already done\n",
      "005850 already done\n",
      "005860 already done\n",
      "005870 already done\n",
      "005880 already done\n",
      "005930 already done\n",
      "005940 already done\n",
      "005950 already done\n",
      "005960 already done\n",
      "005990 already done\n",
      "006040 already done\n",
      "006050 already done\n",
      "006060 already done\n",
      "006090 already done\n",
      "006120 already done\n",
      "006140 already done\n",
      "006200 already done\n",
      "006220 already done\n",
      "006260 already done\n",
      "006280 already done\n",
      "006340 already done\n",
      "006360 already done\n",
      "006370 already done\n",
      "006380 already done\n",
      "006390 already done\n",
      "006400 already done\n",
      "006490 already done\n",
      "006570 already done\n",
      "006620 already done\n",
      "006650 already done\n",
      "006660 already done\n",
      "006730 already done\n",
      "006740 already done\n",
      "006800 already done\n",
      "006840 already done\n",
      "006880 already done\n",
      "006890 already done\n",
      "006910 already done\n",
      "006920 already done\n",
      "006980 already done\n",
      "007070 already done\n",
      "007110 already done\n",
      "007120 already done\n",
      "007160 already done\n",
      "007210 already done\n",
      "007280 already done\n",
      "007310 already done\n",
      "007330 already done\n",
      "007340 already done\n",
      "007370 already done\n",
      "007390 already done\n",
      "007460 already done\n",
      "007530 already done\n",
      "007540 already done\n",
      "007570 already done\n",
      "007590 already done\n",
      "007610 already done\n",
      "007660 already done\n",
      "007680 already done\n",
      "007690 already done\n",
      "007700 already done\n",
      "007720 already done\n",
      "007770 already done\n",
      "007810 already done\n",
      "007820 already done\n",
      "007860 already done\n",
      "007980 already done\n",
      "008040 already done\n",
      "008060 already done\n",
      "008110 already done\n",
      "008250 already done\n",
      "008260 already done\n",
      "008290 already done\n",
      "008350 already done\n",
      "008370 already done\n",
      "008420 already done\n",
      "008470 already done\n",
      "008490 already done\n",
      "008500 already done\n",
      "008600 already done\n",
      "008700 already done\n",
      "008730 already done\n",
      "008770 already done\n",
      "008830 already done\n",
      "008870 already done\n",
      "008930 already done\n",
      "008970 already done\n",
      "009070 already done\n",
      "009140 already done\n",
      "009150 already done\n",
      "009160 already done\n",
      "009180 already done\n",
      "009190 already done\n",
      "009200 already done\n",
      "009240 already done\n",
      "009270 already done\n",
      "009290 already done\n",
      "009300 already done\n",
      "009310 already done\n",
      "009320 already done\n",
      "009420 already done\n",
      "009440 already done\n",
      "009450 already done\n",
      "009460 already done\n",
      "009470 already done\n",
      "009520 already done\n",
      "009540 already done\n",
      "009580 already done\n",
      "009620 already done\n",
      "009680 already done\n",
      "009730 already done\n",
      "009770 already done\n",
      "009780 already done\n",
      "009810 already done\n",
      "009830 already done\n",
      "009900 already done\n",
      "009970 already done\n",
      "010040 already done\n",
      "010060 already done\n",
      "010100 already done\n",
      "010120 already done\n",
      "010130 already done\n",
      "010140 already done\n",
      "010170 already done\n",
      "010240 already done\n",
      "010280 already done\n",
      "010400 already done\n",
      "010420 already done\n",
      "010470 already done\n",
      "010580 already done\n",
      "010600 already done\n",
      "010620 already done\n",
      "010640 already done\n",
      "010660 already done\n",
      "010690 already done\n",
      "010770 already done\n",
      "010780 already done\n",
      "010820 already done\n",
      "010950 already done\n",
      "010960 already done\n",
      "011000 already done\n",
      "011040 already done\n",
      "011070 데이터베이스에 저장 완료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "from pykrx import stock\n",
    "import datetime\n",
    "import os\n",
    "# from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import configparser\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# 대기 시간 설정 함수\n",
    "def random_sleep(min_seconds=0.5, max_seconds=1.5):\n",
    "    time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "    \n",
    "\"\"\"\n",
    "# 설정 파일 읽기\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "username = config['mysql']['username']\n",
    "password = config['mysql']['password']\n",
    "host = config['mysql']['host']\n",
    "database = config['mysql']['database']\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ConfigParser 객체 생성\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# config.ini 파일 경로 설정\n",
    "config_file_path = 'E:\\\\AI\\\\pythonProject\\\\venv\\\\masicsplit\\\\config.ini'\n",
    "\n",
    "# 경로가 올바른지 확인\n",
    "if os.path.exists(config_file_path):\n",
    "    print(\"config.ini 파일을 찾았습니다.\")\n",
    "    config.read(config_file_path)\n",
    "else:\n",
    "    print(\"config.ini 파일을 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "\n",
    "# mysql 섹션에서 설정값 가져오기\n",
    "try:\n",
    "    username = config['mysql']['user']\n",
    "    password = config['mysql']['password']\n",
    "    host = config['mysql']['host']\n",
    "    database=config['mysql']['database']\n",
    "except KeyError as e:\n",
    "    print(f\"설정 파일에서 키를 찾을 수 없습니다: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"기타 오류 발생: {e}\")\n",
    "    \n",
    "    \n",
    "conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 조건 설정\n",
    "per_threshold = 100\n",
    "pbr_threshold = 10\n",
    "div_threshold = 0  # 기준금리 참조\n",
    "\n",
    "# 현재 날짜 기준으로 최근 월 종목 리스트 수집\n",
    "current_date = datetime.datetime.now()\n",
    "last_month_str = current_date.strftime(\"%Y%m\") + '01'\n",
    "\n",
    "# 데이터베이스에서 모든 티커 가져오기\n",
    "cur.execute(\"SELECT ticker FROM ticker_list\")\n",
    "all_tickers = [row[0] for row in cur.fetchall()]\n",
    "\n",
    "# 각 티커에 대한 처리\n",
    "for ticker in all_tickers:\n",
    "    # 이미 처리된 티커는 스킵\n",
    "    cur.execute(f\"SELECT status FROM ticker_status WHERE ticker = '{ticker}'\")\n",
    "    status = cur.fetchone()\n",
    "    if status and status[0] == 'completed':\n",
    "        continue\n",
    "    \n",
    "     # 티커의 끝자리가 0이 아닌 경우 스킵\n",
    "    if ticker[-1] != '0':\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} skipped because it does not end with 0')\n",
    "        continue \n",
    "       \n",
    "   \n",
    "    # 데이터베이스에서 마지막 날짜 확인\n",
    "    cur.execute(f\"SELECT MAX(date) FROM stock_data WHERE ticker = '{ticker}'\")\n",
    "    last_date = cur.fetchone()[0]\n",
    "    # 마지막 날짜가 현재 날짜와 30일 이하로 차이나는 경우 continue\n",
    "    if last_date: # 이미 저장된 데이터가 있다면\n",
    "        last_recorded_date = pd.to_datetime(last_date)\n",
    "        if (current_date - last_recorded_date).days <= 1:\n",
    "            print(f'{ticker} already done')\n",
    "            continue\n",
    "    random_sleep()\n",
    "    name = stock.get_market_ticker_name(ticker)\n",
    "    if \"스팩\" in name:\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} skipped because it called {name}')\n",
    "        continue\n",
    "    # 새 데이터를 가져옴\n",
    "    if last_date:\n",
    "        start_date = (last_date + datetime.timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "    else:\n",
    "        start_date = \"19800102\"\n",
    "    \n",
    "    end_date = current_date.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    random_sleep()\n",
    "    df2 = stock.get_market_fundamental(start_date, end_date, ticker)\n",
    "    if df2.empty or 'PER' not in df2.columns:\n",
    "    \n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "    \n",
    "        print(f'{ticker} no.2 pass condition')\n",
    "        random_sleep()\n",
    "        continue\n",
    "    '''\n",
    "    # 조건 확인\n",
    "    if ('PER' in df2.columns and 'PBR' in df2.columns and 'DIV' in df2.columns):\n",
    "        condition = (df2['PER'] > 0) & (df2['PER'] <= per_threshold) & \\\n",
    "                    (df2['PBR'] > 0) & (df2['PBR'] <= pbr_threshold) & \\\n",
    "                    (df2['DIV'] >= div_threshold)\n",
    "        if not condition.any() and last_date is None:  #조건을 만족하지 않거나 새로운데이터가 없으면 해당 종목은 종료(completed)\n",
    "            cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "            conn.commit()\n",
    "            print(f'{ticker} no.3 pass condition')\n",
    "            time.sleep(5.5)  \n",
    "            continue  # 조건을 만족하지 않으면 다음 티커로 넘어감\n",
    "        \n",
    "    else:\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} no.4 pass condition')\n",
    "        continue  # 필요한 컬럼이 없으면 넘어감\n",
    "    '''        \n",
    "    random_sleep()\n",
    "    df1 = stock.get_market_ohlcv(start_date, end_date, ticker)\n",
    "    \n",
    "\n",
    "    if df1.empty:\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} no.5 pass condition')\n",
    "        random_sleep()\n",
    "        continue\n",
    "\n",
    "    # '고가' 컬럼이 있는지 확인\n",
    "    if '고가' not in df1.columns:\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} no.6 pass condition')\n",
    "        random_sleep()\n",
    "        continue\n",
    "    random_sleep()\n",
    "    df3 = stock.get_market_cap(start_date, end_date, ticker)\n",
    "    \n",
    "    \n",
    "    df1.reset_index(inplace=True)\n",
    "    df2.reset_index(inplace=True)\n",
    "    df3.reset_index(inplace=True)\n",
    "    # 컬럼명 통일\n",
    "    df1.rename(columns={\n",
    "        '날짜': 'date',\n",
    "        '시가': 'open',\n",
    "        '고가': 'high',\n",
    "        '저가': 'low',\n",
    "        '종가': 'close',\n",
    "        '거래량': 'volume',\n",
    "        \n",
    "    }, inplace=True)\n",
    "\n",
    "    df2.rename(columns={\n",
    "        '날짜': 'date',\n",
    "        'PER': 'PER',\n",
    "        'PBR': 'PBR',\n",
    "        'DIV': 'dividend',\n",
    "        'BPS': 'BPS',\n",
    "        'EPS': 'EPS',\n",
    "        'DPS': 'DPS'\n",
    "    }, inplace=True)\n",
    "\n",
    "    df3.rename(columns={\n",
    "        '날짜': 'date',\n",
    "        '시가총액': 'market_cap',\n",
    "        '상장주식수': 'shares_outstanding',\n",
    "        '거래대금': 'value',\n",
    "        '거래량': 'volume'\n",
    "        \n",
    "    }, inplace=True)\n",
    "\n",
    "    \n",
    "     # 날짜 기준으로 결합하고 중복된 열 제거\n",
    "    merged_df = pd.merge(df1, df2, on='date', how='left', suffixes=('', '_duplicate'))\n",
    "    merged_df = pd.merge(merged_df, df3, on='date', how='left', suffixes=('', '_duplicate'))\n",
    "    \n",
    "    # 중복된 열 제거\n",
    "    for column in merged_df.columns:\n",
    "        if 'duplicate' in column:\n",
    "            base_column = column.replace('_duplicate', '')\n",
    "            if base_column in merged_df.columns:\n",
    "                merged_df.drop(column, axis=1, inplace=True)\n",
    "    \n",
    "    # 필요한 열만 남기기\n",
    "    merged_df = merged_df[['date', 'open', 'high', 'low', 'close', 'volume', 'value', 'market_cap', 'shares_outstanding', 'PER', 'PBR', 'dividend', 'BPS', 'EPS', 'DPS']]\n",
    "    # merged_df 상태 출력\n",
    "  \n",
    "    # NaN 값을 None으로 변환 (개별적으로 처리)\n",
    "    merged_df = merged_df.replace({np.nan: None})\n",
    "    # # merged_df 상태 출력\n",
    "    # print(\"merged_df:\")\n",
    "    # print(merged_df.head())\n",
    "\n",
    "    merged_df['ticker'] = ticker\n",
    "    merged_df['name'] = name\n",
    "  \n",
    "    \n",
    "\n",
    "    # 기존 데이터를 가져와서 새로운 데이터와 결합\n",
    "    if last_date:\n",
    "        cur.execute(f\"SELECT * FROM stock_data WHERE ticker = '{ticker}' AND date <= '{last_date}'\")\n",
    "        existing_data = pd.DataFrame(cur.fetchall(), columns=['ticker', 'name', 'date', 'open', 'high', 'low', 'close', 'volume', 'value', 'market_cap', 'shares_outstanding', 'PER', 'PBR', 'dividend', 'BPS', 'EPS', 'DPS','normalized_value'])\n",
    "        existing_data['date'] = pd.to_datetime(existing_data['date'])\n",
    "        existing_data.set_index('date', inplace=True)\n",
    "        merged_df.set_index('date', inplace=True)\n",
    "        combined_df = pd.concat([existing_data, merged_df], axis=0, join='outer')\n",
    "          # 여기서 결합 전에 각 데이터프레임 확인\n",
    "\n",
    "        \n",
    "    else: # 기존데이터가 없으면 로드된 세 DF만 결합\n",
    "        combined_df = merged_df\n",
    "    # print(combined_df)\n",
    "        \n",
    "        \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    combined_df['min_close'] = combined_df['close'].rolling(window=252*5, min_periods=252).min()\n",
    "    combined_df['max_close'] = combined_df['close'].rolling(window=252*5, min_periods=252).max()\n",
    "\n",
    "    # 각 행에 대해 'min_close'와 'max_close'가 0이 아닌지 확인하여 'normalized_value' 계산\n",
    "    def calculate_normalized_value(row):\n",
    "        if pd.notnull(row['min_close']) and pd.notnull(row['max_close']) and (row['max_close'] - row['min_close']) != 0:\n",
    "            return (row['close'] - row['min_close']) / (row['max_close'] - row['min_close']) * 100\n",
    "        else:\n",
    "            return None\n",
    "    try:\n",
    "        combined_df['normalized_value'] = combined_df.apply(calculate_normalized_value, axis=1)\n",
    "    except TypeError as e:\n",
    "        print(f\"TypeError encountered: {e}\")\n",
    "        \n",
    "        print(f'{ticker} no.7 pass condition')\n",
    "        continue\n",
    "\n",
    "    if combined_df['normalized_value'].isnull().all():\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "        print(f'{ticker} no.8 pass condition')\n",
    "        continue\n",
    "\n",
    "\n",
    "    combined_df.reset_index(inplace=True)\n",
    "    \n",
    "    combined_df = combined_df.replace({np.nan: None})\n",
    "    \n",
    "\n",
    "    # 데이터베이스에 저장\n",
    "    for _, row in combined_df.iterrows():\n",
    "        sql = '''\n",
    "        INSERT INTO stock_data (ticker, name, date, open, high, low, close, volume, value, market_cap, shares_outstanding, PER, PBR, dividend, BPS, EPS, DPS, normalized_value)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "            open=VALUES(open),\n",
    "            high=VALUES(high),\n",
    "            low=VALUES(low),\n",
    "            close=VALUES(close),\n",
    "            volume=VALUES(volume),\n",
    "            value=VALUES(value),\n",
    "            market_cap=VALUES(market_cap),\n",
    "            shares_outstanding=VALUES(shares_outstanding),\n",
    "            PER=VALUES(PER),\n",
    "            PBR=VALUES(PBR),\n",
    "            dividend=VALUES(dividend),\n",
    "            BPS=VALUES(BPS),\n",
    "            EPS=VALUES(EPS),\n",
    "            DPS=VALUES(DPS),\n",
    "            normalized_value=VALUES(normalized_value)\n",
    "        '''\n",
    "        cur.execute(sql, (\n",
    "            row['ticker'],\n",
    "            row['name'],\n",
    "            row['date'].strftime('%Y-%m-%d') if row['date'] else None,\n",
    "            row['open'],\n",
    "            row['high'],\n",
    "            row['low'],\n",
    "            row['close'],\n",
    "            int(row['volume']) if row['volume'] is not None else None,\n",
    "            int(row['value']) if row['value'] is not None else None,\n",
    "            int(row['market_cap']) if row['market_cap'] is not None else None,\n",
    "            int(row['shares_outstanding']) if row['shares_outstanding'] is not None else None,\n",
    "            row['PER'],\n",
    "            row['PBR'],\n",
    "            row['dividend'],\n",
    "            row['BPS'],\n",
    "            row['EPS'],\n",
    "            row['DPS'],\n",
    "            row['normalized_value']\n",
    "        ))\n",
    "\n",
    "    conn.commit()\n",
    "     # 최근 60일 동안 데이터가 있는지 확인\n",
    "    last_recorded_date = pd.to_datetime(combined_df['date']).max()\n",
    "    if (current_date - last_recorded_date).days > 60:\n",
    "        print(current_date - last_recorded_date,current_date,last_recorded_date)\n",
    "        cur.execute(f\"UPDATE ticker_status SET status = 'completed' WHERE ticker = '{ticker}'\")\n",
    "        conn.commit()\n",
    "    print(f\"{ticker} 데이터베이스에 저장 완료\")\n",
    "    random_sleep()  \n",
    "\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"모든 데이터가 성공적으로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f1ae9",
   "metadata": {},
   "source": [
    "## ETF 이름 & 티커 리스트 생성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8203cf2a-763d-497a-8b5c-474809798158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롬 드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')  # 브라우저 창을 띄우지 않음\n",
    "options.add_argument('disable-gpu')  # GPU 가속 비활성화\n",
    "options.add_argument('lang=ko_KR')  # 한국어 페이지\n",
    "\n",
    "# 크롬 드라이버 초기화\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d37eebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel 파일로 저장되었습니다: etf_list.xlsx\n",
      "MySQL 데이터베이스에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import configparser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# 설정 파일 읽기\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "username = config['mysql']['username']\n",
    "password = config['mysql']['password']\n",
    "host = config['mysql']['host']\n",
    "database = config['mysql']['database']\n",
    "\n",
    "# MySQL 연결\n",
    "conn = pymysql.connect(host=host, user=username, password=password, db=database, charset='utf8')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 크롬 드라이버 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')  # 브라우저 창을 띄우지 않음\n",
    "options.add_argument('disable-gpu')  # GPU 가속 비활성화\n",
    "options.add_argument('lang=ko_KR')  # 한국어 페이지\n",
    "\n",
    "# 크롬 드라이버 초기화\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "# URL에서 HTML 컨텐츠를 가져옴\n",
    "url = 'https://finance.naver.com/sise/etf.naver'\n",
    "driver.get(url)\n",
    "\n",
    "# 종목명과 티커를 추출하여 리스트로 저장\n",
    "etf_data = []\n",
    "rows = driver.find_elements(By.CSS_SELECTOR, '#etfItemTable > tr')\n",
    "for row in rows:\n",
    "    name_col = row.find_elements(By.CSS_SELECTOR, 'td.ctg a')\n",
    "    if name_col:\n",
    "        name = name_col[0].text.strip()\n",
    "        ticker = name_col[0].get_attribute('href').split('=')[-1]  # 종목명 링크에서 티커 추출\n",
    "        etf_data.append([name, ticker])\n",
    "\n",
    "# 드라이버 종료\n",
    "driver.quit()\n",
    "\n",
    "# DataFrame 생성\n",
    "df = pd.DataFrame(etf_data, columns=['종목명', '티커'])\n",
    "\n",
    "# DataFrame을 Excel 파일로 저장\n",
    "excel_filename = 'etf_list.xlsx'\n",
    "df.to_excel(excel_filename, index=False)\n",
    "print(f\"Excel 파일로 저장되었습니다: {excel_filename}\")\n",
    "\n",
    "# DataFrame을 MySQL에 저장\n",
    "create_table_query = '''\n",
    "CREATE TABLE IF NOT EXISTS etf_list (\n",
    "    name VARCHAR(100),\n",
    "    ticker VARCHAR(20),\n",
    "    PRIMARY KEY (ticker)\n",
    ")\n",
    "'''\n",
    "cur.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# MySQL에 데이터 삽입\n",
    "for index, row in df.iterrows():\n",
    "    insert_query = '''\n",
    "    INSERT INTO etf_list (name, ticker) VALUES (%s, %s)\n",
    "    ON DUPLICATE KEY UPDATE name=VALUES(name)\n",
    "    '''\n",
    "    cur.execute(insert_query, (row['종목명'], row['티커']))\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "print(\"MySQL 데이터베이스에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
